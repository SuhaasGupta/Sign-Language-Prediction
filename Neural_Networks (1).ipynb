{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install tensoeflow\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-241a7ff4c827>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#Importing all the required packages: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Activation\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.constraints import maxnorm\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sign_mnist_train.csv') \n",
    "test = pd.read_csv('sign_mnist_test.csv')\n",
    "\n",
    "trainlabels = train['label'].values\n",
    "train.drop('label', axis = 1, inplace = True)\n",
    "train /= 255\n",
    "images = train.values\n",
    "#images = np.array([np.reshape(i, (28, 28)) for i in images])\n",
    "#images = np.array([i.flatten() for i in images])\n",
    "\n",
    "testlabels = test['label'].values\n",
    "test.drop('label', axis = 1, inplace = True)\n",
    "test /= 255\n",
    "images_test = test.values\n",
    "#images_test = np.array([np.reshape(i, (28, 28)) for i in images_test])\n",
    "#images_test = np.array([i.flatten() for i in images_test])\n",
    "\n",
    "label_binrizer = LabelBinarizer()\n",
    "trainlabels = label_binrizer.fit_transform(trainlabels)\n",
    "testlabels = label_binrizer.fit_transform(testlabels)\n",
    "\n",
    "input_size = images.shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Base Model. Dense Network:\n",
    "model = Sequential([\n",
    " Dense(24,input_shape=(784,),activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(lr=0.1),\n",
    " loss='categorical_crossentropy',\n",
    " metrics=['accuracy'])\n",
    "\n",
    "model.fit(images, trainlabels)\n",
    "\n",
    "model.evaluate(images_test, testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Grid Search - Dense Network:\n",
    "#Building the model skeleton:\n",
    "def create_model(activation = 'sigmoid', dropout_rate = 0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim = input_size, kernel_initializer = 'uniform',\n",
    "                   activation = activation, kernel_constraint = maxnorm(4)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(24, kernel_initializer = 'uniform', activation = activation))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model, batch_size = 1000, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [3,7]\n",
    "batch_size = [1000, 2000]\n",
    "activation =  ['relu', 'tanh', 'sigmoid']\n",
    "#optimizer = ['sgd', 'adam']\n",
    "dropout_rate = [0.0, 0.1, 0.2]\n",
    "\n",
    "param_grid = dict(epochs = epochs, batch_size = batch_size, activation = activation, dropout_rate = dropout_rate)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = 1)\n",
    "grid_result = grid.fit(images,trainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Printing the optimum values of activation function, batch size and drop out rates\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model with the optimum values extracted from the grid search\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim = input_size, kernel_initializer = 'uniform', activation = 'relu', kernel_constraint = maxnorm(4)))\n",
    "model.add(Dropout(0.0))\n",
    "model.add(Dense(24, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(images, trainlabels, validation_split = 0.2, epochs = 3, batch_size = 1000)\n",
    "model.evaluate(images_test, testlabels, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Impute the best parameters here:\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim = input_size, kernel_initializer = 'uniform', activation = activation, kernel_constraint = maxnorm(4)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(24, kernel_initializer = 'uniform', activation = activation))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(images,trainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(images_test, testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array([np.reshape(x,(28,28,1)) for x in images])\n",
    "images_test = np.array([np.reshape(x, (28,28,1)) for x in images_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. CNN - Base:\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation = 'relu', input_shape=(28,28,1,)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (5,5), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(84, activation = 'relu'))\n",
    "model.add(Dense(24, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1000)\n",
    "early_stopping_monitor = EarlyStopping(patience = 2)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(images, trainlabels, validation_split = 0.3, epochs = 20, batch_size = 128, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(images_test, testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(testlabels.argmax(axis=1), pred.argmax(axis=1))\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(confusion_matrix,cbar=False,annot=True,ax=ax,annot_kws={\"size\": 9},fmt=\"d\",cmap= \"Blues\", center = 50, vmin = 5, vmax = 150);\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "ax.xaxis.set_ticklabels([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\"])\n",
    "ax.yaxis.set_ticklabels([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 4: Conv-Pool-Conv-Pool\n",
    "model = Sequential([\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu',input_shape = (28,28,1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1000)\n",
    "early_stopping_monitor = EarlyStopping(patience = 2)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(images, trainlabels, validation_split = 0.3, epochs = 20, batch_size = 128, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(images_test, testlabels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
